#! /usr/bin/env python

import sys
reload(sys)
sys.setdefaultencoding('utf-8')
import os
from os.path import expanduser, isdir, dirname
import subprocess
from datetime import datetime

import time
import argparse
from argparse import ArgumentDefaultsHelpFormatter
import ConfigParser

INC = "https://foo.service-now.com/service-portal/view-incident.do?n="
RQF = "https://foo.service-now.com/service-portal/view-request.do?n="
TIMEINFMT = '%d-%m-%Y %H:%M:%S %Z'
TIMEOUTFMT = '%Y-%m-%d'
MAXWIDTH = 11 # Allow for about 100 M ticketses
DATEWIDTH = 10
ASSIGNEEWIDTH = 15
GROUPWIDTH = 15
CSVNAME = 'snowplough.csv'

VIMCMDS = [
           '+set fdm=marker ic',
           '+sy region snowHead start=/^\d\d-\d\d-\d\{4\}/ end=/View))\?/',
           '+hi link snowHead String',
          ]

# TODO Remove explicit unicode functions?

'''
Type: List
Table: Task [task] (because 'My Work' is about tasks

Green means you already have it.
Nothing is red is either available or interesting.

 0 Number
 1 Created
 2 Short Description
 3 Assignment group
 4 Assigned to
 5 Caller
   Solution (Customer View) -- Solution is in comments too
 6 GGUS ID
 7 Description
 8 Close notes (Internal View)
 9 Additional comments (Customer View)
10 Work notes (Internal View)

'Updated by' could be useful if can search for our whole group

Assigment group is javascript:getMyGroups()
'''

def mkdirs(path):
    if not os.path.isdir(path):
        try:
            if not os.path.isdir(dirname(path.rstrip('/'))):
                os.mkdir(dirname(path.rstrip('/')))
            os.mkdir(path)
        except OSError, e:
            print >>sys.stderr, "Couldn't create index directory"
            print >>sys.stderr, e
            raise

def shortdescwidth():
    out, _ = subprocess.Popen(['stty', 'size'],
                              stdout=subprocess.PIPE).communicate()
    _, w = out.split()

    return int(w) - MAXWIDTH - 4 - DATEWIDTH - ASSIGNEEWIDTH - GROUPWIDTH

def fields(indexpath):
    from whoosh.index import open_dir

    try:
        ix = open_dir(indexpath)
    except IOError, e:
        print >>sys.stderr, e
        return 1
    except whoosh.index.EmptyIndexError, e:
        print >>sys.stderr, e
        return 1

    for n in ix.schema.names():
        print n

def mkix(indexpath, snowfile, csvname, quiet):
    import zipfile, csv
    from whoosh.index import create_in
    from whoosh.fields import Schema, TEXT, DATETIME

    # Create index directory if it's not there yet
    try:
        mkdirs(indexpath)
    except OSError, e:
        return 1

    # Whoosh schema
    schema = Schema(number=TEXT(stored=True),
                    created=DATETIME(stored=True),
                    shortdesc=TEXT(stored=True),
                    group=TEXT(stored=True),
                    assignee=TEXT(stored=True),
                    # solution=TEXT(stored=True), # Solution is in comments too
                    desc=TEXT(stored=True),
                    closenotes=TEXT(stored=True),
                    comments=TEXT(stored=True),
                    worknotes=TEXT(stored=True),
                   )
    ix = create_in(indexpath, schema)

    # Index CSV rows
    writer = ix.writer()
    try:
        z = zipfile.ZipFile(snowfile)
        f = z.open(csvname)
    except zipfile.BadZipfile:
        f = open(snowfile)
    except KeyError, e:
        print >>sys.stderr, e.message
        return 1

    try:
        reader = csv.reader(f)
        reader.next() # Skip header

        t0 = time.time()
        for i, row in enumerate(reader, 1):
            writer.add_document(number=unicode(row[0]),
                                created=datetime.strptime(row[1], TIMEINFMT),
                                shortdesc=row[2].decode('latin-1'),
                                group=row[3].decode('latin-1'),
                                assignee=row[4].decode('latin-1'),
                                # solution=row[6].decode('latin-1'),
                                desc=row[7].decode('latin-1'),
                                closenotes=row[8].decode('latin-1'),
                                comments=row[9].decode('latin-1'),
                                worknotes=row[10].decode('latin-1'),
                               )
            if not quiet and i % 50 == 0:
                print "Indexing %%0%dd ticketses\r" % (MAXWIDTH - 3) % i,
                sys.stdout.flush()
        if not quiet:
            print "Indexing %%0%dd\n" % (MAXWIDTH - 3) % i,
            print "Committing..."
        writer.commit()
        if not quiet:
            print "Indexed %d ticketses in %.2f s" % (i, time.time() - t0)
        
    except KeyboardInterrupt:
        pass

def vim(f, result):
    print >>f, "{{{ %s %s" % (result['number'], result['shortdesc'])
    print >>f, '%s -- %s, %s' % (result['created'].strftime(TIMEOUTFMT),
                                 result['assignee'],
                                 result['group'],
                                )
    if result['number'][:3] == 'INC':
        print >>f, INC + result['number']
    else: 
        print >>f, RQF + result['number']

    for k, l in zip(('desc', 'closenotes', 'comments', 'worknotes'),
                    ('Description', 'Close Notes', 'Comments', 'Work Notes')):
        if result[k]:
            print >>f, "{{{ " + l
            print >>f, result[k].replace('\r', '')
            print >>f, "}}}"

    print >>f, "}}}"

def search(indexpath, tmppath, keyword, dosort, dovim):
    import tempfile, codecs
    from whoosh.index import open_dir, EmptyIndexError

    try:
        ix = open_dir(indexpath)
    except IOError, e:
        print >>sys.stderr, e
        return 1
    except EmptyIndexError, e:
        print >>sys.stderr, e
        return 1

    with ix.searcher() as searcher:
        # Build query
        if keyword == ['*']: # Just list
            from whoosh.qparser import QueryParser
            parser = QueryParser('number', ix.schema)
        else:
            from whoosh.qparser import MultifieldParser
            from whoosh.qparser.dateparse import DateParserPlugin

            parser = MultifieldParser(['shortdesc', 'desc',
                                       'closenotes', 'comments', 'worknotes'],
                                      ix.schema)
            parser.add_plugin(DateParserPlugin(basedate=datetime.now(),
                                               free=True))
        query = parser.parse(unicode(' '.join(keyword)))

        # Start Vim
        if dovim:
            # Create index directory if it's not there yet
            try:
                mkdirs(tmppath)
            except OSError, e:
                return 1

            # Open tempfile
            f = tempfile.NamedTemporaryFile(suffix='-snowplough', dir=tmppath)
            uf = codecs.open(f.name, 'w', 'utf-8')

        # Search and display ticketses
        if dosort:
            results = searcher.search(query, limit=None, sortedby='created')
        else:
            results = searcher.search(query, limit=None)

        if not dovim:
            sdw = shortdescwidth()
        for r in results:
            if dovim:
                vim(uf, r)
            else:
                print "%% %ds %%s %% %ds %% %ds %%s" % \
                    (MAXWIDTH, ASSIGNEEWIDTH, GROUPWIDTH) % \
                    (r['number'],
                     r['created'].strftime(TIMEOUTFMT),
                     r['assignee'][:ASSIGNEEWIDTH],
                     r['group'][:GROUPWIDTH],
                     r['shortdesc'][:sdw])

        if dovim:
            f.flush()
            subprocess.call(['vim'] + VIMCMDS + [f.name])

        # Report
        print >>sys.stderr
        print >>sys.stderr, "Found about %d matching ticketses in %.2f s" % \
            (results.estimated_length(), results.runtime)

def main():
    # Read arguments
    p = argparse.ArgumentParser()
    p.add_argument('-f', '--configfile', type=expanduser, help="config file")

    # Parse fields sub-command
    gl = p.add_argument_group('list indexed fields')
    gl.add_argument('--fields', action='store_true', help="list fields")

    # Parse mkix sub-command
    gm = p.add_argument_group('make index')
    h = '''make index from report FILE, which may be a zip file containing
        a CSV file called CSVNAME (defaulting to %s), or the CSV file
        itself''' % CSVNAME
    gm.add_argument('--mkix', metavar=('FILE', 'CSVNAME'), nargs='+', help=h)
    gm.add_argument('-q', '--quiet', action='store_true',
                    help="don't print out anything")

    # Parse search sub-command
    gs = p.add_argument_group('search tickets')
    h = '''case-insensitive, supports wildcards and fuzzy dates (e.g. vom\*
        created:1 apr to 6 apr 2012)'''
    gs.add_argument('keyword', nargs='*', help=h, default=['*'])
    gs.add_argument('-s', '--sort', action='store_true',
                    help='sort by creation time')
    gs.add_argument('-v', '--vim', action='store_true', help='display in Vim')

    # Parse arguments
    args = p.parse_args()

    # Find and read config files
    defaults = {
                'index': '~/.snowplough/index',
                'tmp':   '~/.snowplough/tmp',
               }
    config = ConfigParser.RawConfigParser(defaults)
    if args.configfile:
        configfiles = args.configfile,
    else:
        configfiles = ('/etc/snowploughrc', expanduser('~/.snowploughrc'))
    config.read(configfiles)
    try:
        indexpath = expanduser(config.get('paths', 'index'))
        tmppath = expanduser(config.get('paths', 'tmp'))
    except ConfigParser.NoSectionError:
        indexpath = expanduser(defaults['index'])
        tmppath = expanduser(defaults['tmp'])

    # Run switch
    if args.fields:
        return fields(indexpath)
    elif args.mkix:
        snowfile = expanduser(args.mkix[0])
        csvname = args.mkix[1] if len(args.mkix) > 1 else CSVNAME
        return mkix(indexpath, snowfile, csvname, args.quiet)
    else:
        return search(indexpath, tmppath, args.keyword, args.sort, args.vim)

if __name__ == '__main__':
    sys.exit(main())
